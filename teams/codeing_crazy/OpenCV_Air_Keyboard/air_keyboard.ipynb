{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV Air Keyboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![The squad](\"https://i.imgur.com/TKT8AoA.jpg\")\n",
    "\n",
    "This is the project for team Codeing Crazy from the 30-Hour PYNQ Hackathon, October 6-7, 2017. Huge thanks to Xilinx for organizing and hosting this.\n",
    "\n",
    "Air Keyboard is an OpenCV-based application that detects objects in the field of view to trigger different musical notes on the overlaid keyboard. It relies heavily on the work of Adrian Rosebrock (https://www.pyimagesearch.com/2015/05/25/basic-motion-detection-and-tracking-with-python-and-opencv/) to do motion detection from video.\n",
    "\n",
    "First, we must include a large number of libraries and instantiate our state machine states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynq.overlays.base import BaseOverlay\n",
    "from pynq.lib.video import *\n",
    "from pynq import PL\n",
    "from PIL import Image as PIL_Image\n",
    "import sys, cv2, math, copy\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "import datetime\n",
    "import imutils\n",
    "import threading \n",
    "\n",
    "# audio states\n",
    "PLAY_NOTHING = 0\n",
    "PLAY_KEY_1   = 1\n",
    "PLAY_KEY_2   = 2\n",
    "PLAY_KEY_3   = 3 \n",
    "PLAY_KEY_4   = 4\n",
    "PLAY_KEY_5   = 5\n",
    "PLAY_KEY_6   = 6\n",
    "PLAY_KEY_7   = 7\n",
    "PLAY_KEY_8   = 8\n",
    "\n",
    "# program states \n",
    "IS_RUNNING = 0\n",
    "IS_STOPPED = 1\n",
    "\n",
    "# program state variables\n",
    "audio_life_state   = IS_RUNNING\n",
    "program_is_running = IS_RUNNING\n",
    "audio_out_state    = PLAY_NOTHING\n",
    "\n",
    "DEBUG = False\n",
    "KEYS = False\n",
    "\n",
    "\n",
    "class NullDevice():\n",
    "\t\"\"\"\n",
    "\tdummy to eat up stdout, thanks to coreygoldberg.blogspot.com!\n",
    "\thttp://coreygoldberg.blogspot.com/2009/05/python-redirect-or-turn-off-stdout-and.html\n",
    "\t\"\"\"\n",
    "\tdef write(self,s):\n",
    "\t\tpass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio:\n",
    "\n",
    "During the project, we learned that the primary method for audio playback in the Pynq is through loading and playing fyles with the base.audio class. Since we knew beforehand the tones we wanted to reproduce, another function was written to generate short samples (roughly 1/6 of a second long per the 44100Hz sample rate) of sin waves corresponding to notes in the 3rd-to-5th octave of the major pentatonic scale. We did some light signal processing to attempt to make our signal as continuous as possible, and then used the library of notes to play out a few times per video frame.  \n",
    "\n",
    "As much of our project appeared to be IO-bound, we used a very simple threading worker to handle our audio playback. We used a global state variable to determine which note should be playing (or whether None should be played), then at every thread wakeup. we played out one of the prerecorded samples and relinquished control to the video thread.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_audio():\n",
    "\t\"\"\"\n",
    "\tSimple threaded program to play out the currently selected note\n",
    "\t(or no note at all) based on the currently detected key\n",
    "\t\"\"\"\n",
    "\twhile audio_life_state == IS_RUNNING:\n",
    "\t\tif   audio_out_state == PLAY_KEY_1:\n",
    "\t\t\taudioout.load(\"notes/Gb3.pdm\")\n",
    "\t\t\taudioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_2:\n",
    "\t\t       audioout.load(\"notes/Ab4.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_3:\n",
    "\t\t       audioout.load(\"notes/Bb4.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_4:\n",
    "\t\t       audioout.load(\"notes/Db4.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_5:\n",
    "\t\t       audioout.load(\"notes/Eb4.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_6:\n",
    "\t\t       audioout.load(\"notes/Gb4.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_7:\n",
    "\t\t       audioout.load(\"notes/Ab5.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\n",
    "\t\telif audio_out_state == PLAY_KEY_8:\n",
    "\t\t       audioout.load(\"notes/Bb5.pdm\")\n",
    "\t\t       audioout.play()\n",
    "\t\t\n",
    "\t\telif audio_out_state == PLAY_NOTHING:\n",
    "\t\t\tpass\n",
    "\t\t\n",
    "\t\tsleep(0.0000001)\n",
    "\n",
    "\tprint(\"Program is over, killing thread\")\n",
    "\treturn\n",
    "\n",
    "\n",
    "\n",
    "#initialize audio\n",
    "base = BaseOverlay(\"base.bit\")\n",
    "audioout = base.audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video\n",
    "\n",
    "This app uses the Logitech C270 USB webcam for video input, and displays the output in crystal clear 640x480 over HDMI. Here we instantiate and configure all objects having to do with the video processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize output HDMI stream\n",
    "my_mode = VideoMode(640, 480, 24)\n",
    "hdmi_out = base.video.hdmi_out\n",
    "hdmi_out.configure(my_mode, None ) \n",
    "hdmi_out.start()\n",
    "print(\"Initialize output_HDMI\")\n",
    "\n",
    "# initialize input USB video capture\n",
    "video_in = cv2.VideoCapture(0)\n",
    "video_in.set(cv2.CAP_PROP_FRAME_WIDTH,  640 )\n",
    "video_in.set(cv2.CAP_PROP_FRAME_HEIGHT, 480 )\n",
    "print(\"Initialize video\")\n",
    "\n",
    "# set video vars \n",
    "cap_region_x_begin=0.5  # start point/total width\n",
    "cap_region_y_end=0.8    # start point/total width\n",
    "threshold = 120         #  BINARY threshold\n",
    "blurValue = 100         # GaussianBlur parameter\n",
    "bgSubThreshold = 350\n",
    "\n",
    "starttime = time()\n",
    "\n",
    "# variables\n",
    "isBgCaptured = 0       # bool, whether the background captured\n",
    "triggerSwitch = False  # if true, keyborad simulator works\n",
    "\n",
    "# initialize the first frame in the video stream\n",
    "firstFrame = None\n",
    "\n",
    "# load keyboard images\n",
    "img_unpressed = cv2.imread(\"pics/unpressed.png\",-1)\n",
    "img_unpressed = cv2.resize(img_unpressed,(79,240),interpolation = cv2.INTER_AREA)\n",
    "unpressed_height,unpressed_width = img_unpressed.shape[:2]\n",
    "img_un_alpha = img_unpressed[:,:,3]/255.0\n",
    "\n",
    "img_pressed = cv2.imread(\"pics/pressed.png\",-1)\n",
    "pressed_height,pressed_width = img_pressed.shape[:2]\n",
    "print(\"Initialize video stream!\")\n",
    "\n",
    "original_stdout = sys.stdout\n",
    "sys.stdout = NullDevice()\n",
    "\n",
    "original_stderr = sys.stderr\n",
    "sys.stderr = NullDevice()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main\n",
    "\n",
    "Here we begin the main loop. A frame of video is captured from the webcam, the key image overlaid, and motion detection performed. The loop also plays a sound file if motion is detected within the relevant space on the screen. It is set to run for 30 seconds before closing itself so we would not get too distracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "\t\"\"\" \n",
    "\tmain loop- grab a frame from webcam, process it, push to HDMI\n",
    "\t\"\"\"\n",
    "\n",
    "\t# start the audio thread\n",
    "\tt = threading.Thread(target=start_audio)\n",
    "\tt.start()\n",
    "\n",
    "\twhile program_is_running == IS_RUNNING:\n",
    "\t\tstart = time()\n",
    "\t\tretcode, frame_vga = video_in.read()\n",
    "\n",
    "\t\t# if the first frame is None, initialize it\n",
    "\t\tif firstFrame is None: \n",
    "\t\t\t# first frame is used for comparison \n",
    "\t\t\toutframe = hdmi_out.newframe()\n",
    "\t\t\toutframe[0:480, 0:640,:] = frame_vga[0:480,0:640,:]\n",
    "\t\t\toutframe1 = cv2.cvtColor(outframe, cv2.COLOR_RGB2GRAY)\n",
    "\t\t\toutframe1 = imutils.resize(outframe1,height=480,width=640)\n",
    "\t\t\tfirstFrame = outframe\n",
    "\t\t\tcontinue\n",
    "\t\t\t\n",
    "\t\telif retcode == True:\n",
    "\t\t\toutframe = hdmi_out.newframe()\n",
    "\t\t\n",
    "\t\t\t# create a copy-frame to manipulate \n",
    "\t\t\toutframe[0:480, 0:640,:] = frame_vga[0:480,0:640,:]\n",
    "\t\t\t\n",
    "\t\t\t#outframe = imutils.resize(outframe, width=500)\n",
    "\t\t\tgray = cv2.cvtColor(outframe, cv2.COLOR_RGB2GRAY)\n",
    "\t\t\tgray = imutils.resize(gray,height=480,width=640)\n",
    "\t\t\talpha_out = 1-img_un_alpha\n",
    "\n",
    "\t\t\t# draw 8 keys on the screen \n",
    "\t\t\tif KEYS:\n",
    "\t\t\t\tfor i in range(8):\n",
    "\t\t\t\t\tfor c in range(3):\n",
    "\t\t\t\t\t\toutframe[120:120+unpressed_height,18+75*i:18+unpressed_width+75*i,c] = (img_un_alpha * img_unpressed[:,:,c]+alpha_out*outframe[120:120+unpressed_height,18+75*i:18+unpressed_width+75*i,c])\n",
    "\t\t\t\n",
    "\t\t\t# compute the absolute difference between the current frame and\n",
    "\t\t\t# first frame\n",
    "\t\t\tframeDelta = cv2.absdiff(outframe1, gray)\n",
    "\t\t\tthresh = cv2.threshold(frameDelta, 25, 255, cv2.THRESH_BINARY)[1]\n",
    " \n",
    "\t\t\t# dilate the thresholded image to fill in holes, then find contours\n",
    "\t\t\t# on thresholded image\n",
    "\t\t\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\t\t\t(im2, contours, hierarchy) = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\t\t \n",
    "\t\t\t# compute the bounding box for the contour, draw it on the frame,\n",
    "\t\t\t# and update the text\n",
    "\t\t\tfor c in contours:\n",
    "\t\t\t\t# if the contour is too small, ignore it\n",
    "\t\t\t\tif cv2.contourArea(c) < 10000:\n",
    "\t\t\t\t\tcontinue\n",
    "\t\t\t\tx, y, w, h = cv2.boundingRect(c)\n",
    "\t\t\t\tif DEBUG:\n",
    "\t\t\t\t\tcv2.rectangle(outframe, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
    "\t\t\t\tM = cv2.moments(c)\n",
    "\n",
    "\t\t\t\t\"\"\"\n",
    "\t\t\t\tthis is the key part of the algorithm\n",
    "\t\t\t\tcompute the centroid of the motion object and\n",
    "\t\t\t\tdetermine whether it falls within a \"key\"\n",
    "\t\t\t\t\"\"\"\t\t\t\t\n",
    "\t\t\t\tcentroid_x = int(M['m10']/M['m00'])\n",
    "\t\t\t\tcentroid_y = int(M['m01']/M['m00'])\n",
    "\n",
    "\t\t\t\tif DEBUG:\n",
    "\t\t\t\t\tprint(centroid_x)\n",
    "\t\t\t\t\tprint(centroid_y)\n",
    "\t\t\t\n",
    "\n",
    "\t\t\t\t# if the centroid is within a key, update audio state\n",
    "\t\t\t\tif(centroid_y > 180 and centroid_y < 420):\n",
    "\t\t\t\t# detect key 1 \n",
    "\t\t\t\t\tif(centroid_x > 20 and centroid_x < 95):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_1\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(20,120),(95,360),(0,255,255),2)\n",
    "\t\t\t\t\t# detect key 2 \n",
    "\t\t\t\t\telif(centroid_x < 170):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_2\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(95,120),(170,360),(255,0,255),2)\n",
    "\t\t\t\t\t# detect key 3\n",
    "\t\t\t\t\telif(centroid_x < 245):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_3\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(170,120),(245,360),(255,255,0),2)\n",
    "\t\t\t\t\t# detect key 4\n",
    "\t\t\t\t\telif(centroid_x < 320):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_4\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(245,120),(320,360),(255,0,0),2)\n",
    "\t\t\t\t\t# detect key 5\n",
    "\t\t\t\t\telif(centroid_x < 395):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_5\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(320,120),(395,360),(0,255,0),2)\n",
    "\t\t\t\t\t# detect key 6\n",
    "\t\t\t\t\telif(centroid_x < 470):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_6\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(395,120),(470,360),(0,255,255),2)\n",
    "\t\t\t\t\t# detect key 7\n",
    "\t\t\t\t\telif(centroid_x < 545):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_7\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(470,120),(545,360),(255,0,255),2)\n",
    "\t\t\t\t\t# detect key 8\n",
    "\t\t\t\t\telif(centroid_x < 620):\n",
    "\t\t\t\t\t\taudio_out_state = PLAY_KEY_8\n",
    "\t\t\t\t\t\tcv2.rectangle(outframe,(545,120),(620,360),(255,255,0),2)\n",
    "\t\t\t\t\t# else play nothing \n",
    "                else:\n",
    "\t\t\t\t\taudio_out_state = PLAY_NOTHING\n",
    "\n",
    "\t\t\thdmi_out.writeframe(outframe)\t\n",
    "\n",
    "\t\t# If capturing a frame fails. print a debug\n",
    "\t\telse:\n",
    "\t\t\tprint(\"Failed!\")\n",
    "\t\t\t#break\n",
    "\t\t\n",
    "\t\t# Run for 40s, then break\n",
    "\t\tif (time()-starttime > 600 ):\n",
    "\t\t\tsys.stdout = original_stdout\n",
    "\t\t\tsys.stderr = original_stderr\n",
    "\t\t\tprint(\"Timeout- terminate program\")\n",
    "\t\t\tprogram_is_running = IS_STOPPED\n",
    "\t\t\taudio_life_state = IS_STOPPED\n",
    "\n",
    "\t# after 30s, close the stream\n",
    "\taudio_life_state = IS_STOPPED\n",
    "\tt.join()\n",
    "\tprint(\"Closing, goodbye!\")\n",
    "\tvideo_in.release()\n",
    "\thdmi_out.stop()\n",
    "\tdel video_in\n",
    "\tdel hdmi_out\n",
    "\tsys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error\n",
    "\n",
    "Some error handling and headache stuff:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO we wish this would work but jupyter is handling SIGINT \n",
    "except KeyboardInterrupt:\n",
    "\tt.join()\n",
    "\tprint(\"Goodbye:keyboard\")\n",
    "\tvideo_in.release()\n",
    "\thdmi_out.stop()\n",
    "\tdel hdmi_out\n",
    "\tdel video_in\n",
    "\tsys.exit()\n",
    "\t\n",
    "# exit gracefully in case of a runtime error \n",
    "except RuntimeError as e:\n",
    "\tprint(\"Goodbye:runtime\")\n",
    "\tprint(e)\n",
    "\tvideo_in.release()\n",
    "\thdmi_out.stop()\n",
    "\tdel hdmi_out\n",
    "\tdel video_in\n",
    "\tt.join()\n",
    "\t#del audioout\n",
    "\tsys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rock on!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
